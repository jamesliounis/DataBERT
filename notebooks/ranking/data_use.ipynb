{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from transformers import GPT2Tokenizer\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import warnings\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/jamesliounis/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Downloading the punkt tokenizer models\n",
    "nltk.download('punkt')\n",
    "\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from utils import *\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import GPT2TokenizerFast\n",
    "from fuzzywuzzy import fuzz\n",
    "import pickle\n",
    "tqdm.pandas()\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>section_title</th>\n",
       "      <th>text</th>\n",
       "      <th>pub_title</th>\n",
       "      <th>cleaned_label</th>\n",
       "      <th>dataset_title</th>\n",
       "      <th>dataset_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>796f35c1-ba6b-4552-8a7f-5d8b61164fb0</td>\n",
       "      <td>Introduction</td>\n",
       "      <td>Grasslands provide key services, especially in...</td>\n",
       "      <td>Land cover dynamics influence distribution of ...</td>\n",
       "      <td>north american breeding bird survey bbs|north ...</td>\n",
       "      <td>North American Breeding Bird Survey (BBS)|Nort...</td>\n",
       "      <td>North American Breeding Bird Survey (BBS)|Nort...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>796f35c1-ba6b-4552-8a7f-5d8b61164fb0</td>\n",
       "      <td>Study area</td>\n",
       "      <td>The study area consisted of the states Oklahom...</td>\n",
       "      <td>Land cover dynamics influence distribution of ...</td>\n",
       "      <td>north american breeding bird survey bbs|north ...</td>\n",
       "      <td>North American Breeding Bird Survey (BBS)|Nort...</td>\n",
       "      <td>North American Breeding Bird Survey (BBS)|Nort...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Id section_title  \\\n",
       "0  796f35c1-ba6b-4552-8a7f-5d8b61164fb0  Introduction   \n",
       "1  796f35c1-ba6b-4552-8a7f-5d8b61164fb0    Study area   \n",
       "\n",
       "                                                text  \\\n",
       "0  Grasslands provide key services, especially in...   \n",
       "1  The study area consisted of the states Oklahom...   \n",
       "\n",
       "                                           pub_title  \\\n",
       "0  Land cover dynamics influence distribution of ...   \n",
       "1  Land cover dynamics influence distribution of ...   \n",
       "\n",
       "                                       cleaned_label  \\\n",
       "0  north american breeding bird survey bbs|north ...   \n",
       "1  north american breeding bird survey bbs|north ...   \n",
       "\n",
       "                                       dataset_title  \\\n",
       "0  North American Breeding Bird Survey (BBS)|Nort...   \n",
       "1  North American Breeding Bird Survey (BBS)|Nort...   \n",
       "\n",
       "                                       dataset_label  \n",
       "0  North American Breeding Bird Survey (BBS)|Nort...  \n",
       "1  North American Breeding Bird Survey (BBS)|Nort...  "
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"/Users/jamesliounis/Documents/Projects/World Bank/NLP Project/data/train_set.csv\")\n",
    "train_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.dropna(inplace = True, subset='text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d75d9691623d4b62967b863e485c8098",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/236628 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize an empty list to collect all the new rows\n",
    "rows_list = []\n",
    "\n",
    "# Using tqdm for a progress bar\n",
    "for index, row in tqdm(train_df.iterrows(), total=train_df.shape[0]):\n",
    "    # Tokenizing the 'text' field into sentences\n",
    "    sentences = sent_tokenize(str(row['text']))\n",
    "    \n",
    "    # For each sentence, create a new row and add it to the list\n",
    "    for sentence in sentences:\n",
    "        # Instead of copying the DataFrame row, create a new dict\n",
    "        new_row = row.to_dict()\n",
    "        new_row['text'] = sentence\n",
    "        rows_list.append(new_row)\n",
    "\n",
    "# Concatenate them into a new DataFrame\n",
    "train_df_split = pd.DataFrame(rows_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Since the late 18th century, major land cover changes, such as grassland conversion to cropland and, elsewhere, woody plant encroachment, have occurred across large portions of the Great Plains in North America.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_split.head(5)['text'].to_list()[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Designing a Human-AI-in-the-Loop solution to rank data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using various LLMs (open/closed course) to annotate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the tokenizer once, outside of the function, to avoid reloading it on each function call\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "\n",
    "def limit_string_by_tokens(input_string, max_tokens):\n",
    "    \"\"\"\n",
    "    Truncates the input string to a specified maximum number of tokens using GPT-2 tokenizer.\n",
    "\n",
    "    Args:\n",
    "    input_string (str): The string to be truncated.\n",
    "    max_tokens (int): The maximum number of tokens the output string should contain.\n",
    "\n",
    "    Returns:\n",
    "    str: The truncated string.\n",
    "    \"\"\"\n",
    "    # Tokenize the input string\n",
    "    tokens = tokenizer.tokenize(input_string)\n",
    "\n",
    "    # Truncate the token list if it exceeds the maximum length\n",
    "    if len(tokens) > max_tokens:\n",
    "        truncated_tokens = tokens[:max_tokens]\n",
    "        # Convert the truncated token list back to a string\n",
    "        limited_string = tokenizer.convert_tokens_to_string(truncated_tokens)\n",
    "    else:\n",
    "        limited_string = input_string\n",
    "\n",
    "    return limited_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n\"result\": {\"1992 survey\": [\"1\", \"0\"]},\\n\"explanation\": \"The 1992 survey is mentioned in the passage as the last survey affected by the wedging procedure, but it is not actively used in the text.\"\\n}'"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### IDENTIFY DATASET IN SENTENCES USING GROQ\n",
    "\n",
    "mixtral = \"mixtral-8x7b-32768\"\n",
    "llama = \"llama2-70b-4096\"\n",
    "\n",
    "model = ChatGroq(model_name=llama, groq_api_key=groq_key, temperature=0)\n",
    "\n",
    "system_message = \"You are a helpful research assistant who can only return answers in the form of dictionaries in JSON format.\"\n",
    "\n",
    "\n",
    "def extract_dictionary(response_str):\n",
    "    \"\"\"\n",
    "    This function aims to extract a dictionary from a given string that may contain\n",
    "    additional text or characters outside the dictionary structure.\n",
    "\n",
    "    :param response_str: The string from which the dictionary will be extracted.\n",
    "    :return: The extracted dictionary if successful, None otherwise.\n",
    "    \"\"\"\n",
    "\n",
    "    # Use a regular expression to find a substring that looks like a dictionary.\n",
    "    # This regex matches a string that starts with '{', ends with '}', and does not contain\n",
    "    # any curly braces in between. The re.DOTALL flag allows '.' to match newlines as well.\n",
    "    dict_str_match = re.search(r\"\\{[^{}]*\\}\", response_str, re.DOTALL)\n",
    "\n",
    "    # Check if a match was found\n",
    "    if dict_str_match:\n",
    "        # Extract the matched dictionary-like string\n",
    "        dict_str = dict_str_match.group(0)\n",
    "\n",
    "        # Remove newlines to avoid JSON parsing errors and replace single quotes with double quotes\n",
    "        # to conform to JSON format. Also, handle nested single quotes properly by ensuring\n",
    "        # instances of \"'s\" are not incorrectly replaced.\n",
    "        dict_str = dict_str.replace(\"\\n\", \"\").replace(\"'\", '\"').replace('\"s', \"'s\")\n",
    "\n",
    "        try:\n",
    "            # Attempt to parse the corrected string as JSON and convert it into a dictionary\n",
    "            result_dict = json.loads(dict_str)\n",
    "            return result_dict\n",
    "        except json.JSONDecodeError as e:\n",
    "            # If JSON parsing fails, print an error message and return None\n",
    "            print(f\"Error parsing the extracted string as JSON: {e}\")\n",
    "            return None\n",
    "    else:\n",
    "        # If no dictionary-like string is found, print an error message and return None\n",
    "        print(\"No dictionary-like string found.\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def identify_dataset_with_groq(passage):\n",
    "    \"\"\"\n",
    "    Analyzes the given passage to identify any specific dataset names using LangChain Groq.\n",
    "\n",
    "    Args:\n",
    "    passage (str): The text passage to analyze.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary with the dataset name and indicators of mention and active use.\n",
    "    \"\"\"\n",
    "\n",
    "    text = f\"\"\"\n",
    "    Understand the following sentence: \"{passage}\".\n",
    "    Your task is to identify if dataset is referenced in the text, assessing its context of mention and use. \n",
    "    You must not identify more than one dataset per text.\n",
    "    You must not identify a dataset if it is not directly mentioned or used in the text. \n",
    "    You must always return a dictionary with two keys: one for the dataset analysis and another for the explanation.\n",
    "    Provide a response strictly adhering to the structured format below without any additional narrative or explanatory text. \n",
    "    You may not provide a response if its criteria do not adhere to any of the 3 categories:\n",
    "    - [0,0] denotes denotes no mention and no active use.\n",
    "    - [1,0] denotes mention but no active use.\n",
    "    - [1,1] denotes mention and active use. \n",
    "\n",
    "    - If no dataset is directly mentioned:\n",
    "    {{\n",
    "        \"result\": {{\"No dataset mentioned\": [\"0\", \"0\"]}},\n",
    "        \"explanation\": \"The specific explanation based on the passage content.\"\n",
    "    }}\n",
    "\n",
    "    - If a dataset is mentioned but not actively used:\n",
    "    {{\n",
    "        \"result\": {{\"Dataset Name\": [\"1\", \"0\"]}},\n",
    "        \"explanation\": \"The specific explanation based on the passage content.\"\n",
    "    }}\n",
    "\n",
    "    - If a dataset is mentioned and actively used:\n",
    "    {{\n",
    "        \"result\": {{\"Dataset Name\": [\"1\", \"1\"]}},\n",
    "        \"explanation\": \"The specific explanation based on the passage content.\"\n",
    "    }}\n",
    "\n",
    "    For instance:\n",
    "    - Passage: \"Our analysis leverages the GPT-3 dataset for training\" should only return: \n",
    "    {{\n",
    "        result:{{\"GPT-3\": [\"1\", \"1\"]}}, \n",
    "        explanation:'This passage clearly mentions the GPT-3 dataset and its usage.'\n",
    "    }}\n",
    "\n",
    "    Additional guidelines:\n",
    "    - Define a dataset as \"actively used\" if it is integral to the research, analysis, or results being discussed.\n",
    "    - You must distinguish dataset names from other entities such as indicators, citations of other academic papers, figures/tables in papers, or appendixes.\n",
    "    - Make sure to always be coherent in your responses. \n",
    "\n",
    "\n",
    "    Please provide the response in the structured dictionary format as illustrated above, focusing solely on populating the 'result' and 'explanation' fields accurately according to the guidelines provided, with no additional text or context.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    text = limit_string_by_tokens(text, 3800)\n",
    "    response = \"\"\n",
    "    for chunk in model.stream(text):\n",
    "        response += chunk.content\n",
    "\n",
    "    return response\n",
    "\n",
    "\n",
    "# Test with random data entry\n",
    "identify_dataset_with_groq(train_df_split[\"text\"].to_list()[10555])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_dataframe_with_groq_results(df):\n",
    "    \"\"\"\n",
    "    This function updates a DataFrame by adding new columns based on the results\n",
    "    obtained from a GROQ (Graph-Relational Object Queries) model. These results\n",
    "    include whether data is present, if data was used, the name of the dataset,\n",
    "    and an explanation of the model's output.\n",
    "\n",
    "    :param df: The DataFrame to be updated, which must contain a 'text' column.\n",
    "    :return: The updated DataFrame with new columns related to GROQ model results.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize new columns in the DataFrame to store the results.\n",
    "    # 'has_data': Boolean flag indicating if relevant data was found.\n",
    "    # 'data_used': Boolean flag indicating if the data was used in analysis.\n",
    "    # 'dataset_name': The name of the dataset identified (if any).\n",
    "    # 'explanation': Textual explanation of the analysis result.\n",
    "    df['has_data'] = False\n",
    "    df['data_used'] = False\n",
    "    df['dataset_name'] = None\n",
    "    df['explanation'] = None\n",
    "    \n",
    "    # Iterate over each row in the DataFrame. 'tqdm' is used to show a progress bar.\n",
    "    for index, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "        # Extract the text from 'text' column of the DataFrame.\n",
    "        passage = row['text']\n",
    "        \n",
    "        # The function returns a dictionary containing the analysis results.\n",
    "        model_output = identify_dataset_with_groq(passage)\n",
    "        \n",
    "        # Verify the model output contains expected keys: 'result' and 'explanation'.\n",
    "        if model_output and 'result' in model_output and 'explanation' in model_output:\n",
    "            # Extract the first key-value pair from the 'result' dictionary.\n",
    "            result_key, result_values = next(iter(model_output['result'].items()))\n",
    "            \n",
    "            # Check if the key is meaningful (not 'null' or an empty string).\n",
    "            if result_key.lower() != 'null' and result_key != \"\":\n",
    "                # Update the DataFrame with the analysis results.\n",
    "                # A value of '1' in result_values indicates 'true'.\n",
    "                df.at[index, 'has_data'] = result_values[0] == '1'\n",
    "                df.at[index, 'data_used'] = result_values[1] == '1'\n",
    "                # Assign the dataset name if 'has_data' is true; otherwise, leave as None.\n",
    "                df.at[index, 'dataset_name'] = result_key if df.at[index, 'has_data'] else None\n",
    "            else:\n",
    "                # If the result key is not meaningful, update the DataFrame to reflect no data was found.\n",
    "                df.at[index, 'has_data'] = False\n",
    "                df.at[index, 'data_used'] = False\n",
    "                df.at[index, 'dataset_name'] = None\n",
    "            \n",
    "            # Update the 'explanation' column with the explanation from the model output.\n",
    "            df.at[index, 'explanation'] = model_output['explanation']\n",
    "    \n",
    "    # Return the updated DataFrame.\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining path to save data\n",
    "\n",
    "PATH = '/Users/jamesliounis/Documents/Projects/World Bank/NLP Project/Documents/GeneratedData/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "409fdc8b2261439d8ed1beaebe736272",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Suppress all warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# Define lambda function\n",
    "get_response = lambda text: identify_dataset_with_groq(text)\n",
    "\n",
    "# Load dataset of 90000 rows\n",
    "df = train_df_split.head(90000)\n",
    "\n",
    "# Define output path\n",
    "output_path = PATH + 'annotated_data_90000.xlsx'\n",
    "\n",
    "# Initialize an ExcelWriter object\n",
    "with pd.ExcelWriter(output_path) as writer:\n",
    "    # Process the DataFrame in chunks\n",
    "    for start in tqdm(range(0, len(df), 20)):  # Adjust the chunk size as needed\n",
    "        end = min(start + 20, len(df))\n",
    "        chunk = df[start:end]\n",
    "        \n",
    "        # Apply the get_response function to the 'text' column and store directly in 'response'\n",
    "        chunk['response'] = chunk['text'].apply(get_response)\n",
    "        \n",
    "        # Append the processed chunk to the Excel file\n",
    "        # If it's the first chunk, write headers, otherwise, append without headers\n",
    "        chunk.to_excel(writer, sheet_name='Sheet1', startrow=start, index=False, header=not bool(start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                   0\n",
       "section_title     3304\n",
       "text                 3\n",
       "pub_title            0\n",
       "cleaned_label        0\n",
       "dataset_title        0\n",
       "dataset_label        0\n",
       "response         73348\n",
       "dtype: int64"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First issue with API calls - not very little data actually populated\n",
    "\n",
    "train_90000 = pd.read_excel(PATH + 'annotated_data_90000.xlsx')\n",
    "train_90000.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the data that was correctly annotated\n",
    "\n",
    "train_9000_correctly_annotated = train_90000.dropna(subset='response')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73348, 8)"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identifying the data that's missing annotations\n",
    "\n",
    "df_missing_annotation = train_90000[train_90000['response'].isna()]\n",
    "df_missing_annotation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74fd33d6b86e42daa6c58c8edbf1fe1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Responses:   0%|          | 0/73348 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Annotating missing data: 73348 rows\n",
    "\n",
    "file_name = 'annotated_data_73348.csv'\n",
    "\n",
    "# Assuming identify_dataset_with_groq and df_missing_annotation are defined\n",
    "get_response = lambda s: identify_dataset_with_groq(s)\n",
    "\n",
    "# Applying the function with tqdm progress bar\n",
    "tqdm.pandas(desc=\"Processing Responses\")\n",
    "df_missing_annotation['response'] = df_missing_annotation['text'].progress_apply(get_response)\n",
    "\n",
    "# Define the output path for the CSV\n",
    "output_csv_path = PATH + file_name\n",
    "\n",
    "# Write the DataFrame to a CSV file\n",
    "df_missing_annotation.to_csv(output_csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52865385db4646e1ba5ab17d6fe16c71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Responses:   0%|          | 0/200000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Annotating another 200000 rows\n",
    "\n",
    "file_name = 'annotated_data_200000.json'\n",
    "\n",
    "train_200000 = train_df_split.tail(200000)\n",
    "\n",
    "# Assuming identify_dataset_with_groq and df_missing_annotation are defined\n",
    "get_response = lambda s: identify_dataset_with_groq(s)\n",
    "\n",
    "# Applying the function with tqdm progress bar\n",
    "tqdm.pandas(desc=\"Processing Responses\")\n",
    "train_200000['response'] = train_200000['text'].progress_apply(get_response)\n",
    "\n",
    "# Define the output path for the CSV\n",
    "output_path = PATH + file_name\n",
    "\n",
    "# Write the DataFrame to a CSV file\n",
    "train_200000.to_json(output_path, orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the Excel writer\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
