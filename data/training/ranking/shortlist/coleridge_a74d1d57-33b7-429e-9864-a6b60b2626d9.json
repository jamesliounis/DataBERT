{
  "doc_id": "a74d1d57-33b7-429e-9864-a6b60b2626d9",
  "query": "What dataset was used in the paper?",
  "k": 50,
  "shortlist": [
    "Please email the corresponding author if you wish to point some errors or leave a message on the GitHub repository.",
    "The resulting dataset provides some value added regarding its sources.",
    "Their dataset requires some reading to qualify whether, and at which scale, a given measure is implemented.",
    "The dataset can also be related to datasets tracking more specifically government interventions in the economy 5, 9 .",
    "Research assistants then confront the results from the scrapping to web sources and manually coded the items in the CoronaNet dataset.",
    "Our reading of the ACAPS dataset translates the information reported in the ACAPS dataset and scales the selected measures.",
    "They based their data collection on public health institutions, official government sources, peer-reviewed and non-peer reviewed scientific papers, press releases, newspapers articles and social media.",
    "The authors use an artificial intelligence company to scrap the press related to COVID-19 and to extract some information on the dates and scales of implementation of a wide range of public health measures, e.g.",
    "The author used Stata 14 to produce the final spreadsheet.",
    "The verifications on the first versions of the dataset are listed in the Stata do file \"verif.do\" in the former version of the dataset in the GitHub repository.",
    "www.nature.com/scientificdata www.nature.com/scientificdata/ that includes different variables related to public health, economic interventions, public campaigns and research incentives for a vaccine.",
    "Their dataset is particularly useful in providing information on both the scale and the dates of the measures implemented.",
    "As the ACAPS dataset records the dates of policy measures, modifications were directly made -if necessary -for measures www.nature.com/scientificdata www.nature.com/scientificdata/ implemented between the two rounds of data verification.",
    "For economic measures, the research assistant went through the two sources (IGC if the country was coded in their dataset, IMF if the country was not coded in the IGC) and orally listed for each country the economic measures implemented.",
    "The Response2covid19 dataset complements the efforts made by other researchers in different manners.",
    "The same manual methodology was used for public health measures: the research assistant filtered the ACAPS dataset on the different categories of interventions (lockdowns, movement restrictions, public health measures, and social distancing) and orally listed the measures taken at the country-level with their dates.",
    "The updated versions of the database can be downloaded from GitHub or OpenICPSR in Excel and Stata formats and can be imported into a variety of software programs.",
    "In the first version of the dataset, the principal investigator manually entered the information in an excel file and exchanged with a research assistant and manually checked the accuracy of the coding of the data for each country on a rolling basis.",
    "The data collection is based on news articles and government press releases and briefings.",
    "The coding script (script.do) allows researchers and organizations to assess the accuracy of our dataset and the quality of the sources.",
    "An example is Elgin et al.",
    "A description of the fields in the database is shown below and is available through a data dictionary on the repositories.",
    "The checks on the previous versions of the dataset were done on March 30, April 17, 2020, between May 25 and May 29, between June 29 and July 3 and between July 24 and 31, 2020.",
    "The spreadsheet data is created from the coding script, available on the online repository (\"script.do\").",
    "They based their data collection on official sources and secondary sources such as media reports.",
    "Users of the dataset must keep in mind that countries do not have the same institutional settings.",
    "The dataset is based on manual recording of policy measures implemented all around the world.",
    "The ACAPS dataset provides a full range of information going from political declarations to the detailed implementation of public health or social measures.",
    "The file \"Sources.xls\" in the repository reports, for each country, lists the sources used for the economic and public health measures.",
    "We checked that the coding was accurate using the \"tabulate\" function in Stata for all coded measures.",
    "The dataset codes thirteen public health measures and seven economic policies taken by governments to respond to COVID-19.",
    "The coding of the measures is available in a Stata do file format.",
    "Second, our dataset covers economic measures to a larger extent than Hale et al.",
    "The format of their dataset does not allow us to directly merge their dataset with another one, as they textually report the measures implemented or discussed.",
    "8 coded a structured dataset of non-pharmaceutical interventions divided in 8 themes and 63 categories in 56 countries, the Complexity Science Hub COVID-19 Control Strategies List (CCCSL).",
    "The dataset was simply merged with our baseline dataset.",
    "To do so, the principal investigator used the \"tsline\" function in Stata to graph the time series of the indices to check that there was no unexpected break in the tendencies.",
    "The IMF gives short case studies of countries but does not provide a dataset format or a list of measures per country, so the quality of the information relies on their treatment of the information and our understanding of the measures.",
    "For all variables, except the variable school closures which is in a suitable dataset format by the UNESCO, the coding of the data is done directly in a Stata do file via lines of coding.",
    "Our dataset considers for example elections and enhanced surveillance as key variables, which are to the best of our knowledge not considered by the abovementioned datasets.",
    "The dataset was sent via email to the research assistant who checked that the coding was accurate.",
    "with a decreasing trend at some date or values higher than 0 before any COVID-19 cases was reported -the principal investigator checked that the coding of the measures was accurate and particularly that, at date t-1 before the implementation of a given measure, the coding was 0, and that, at date t + 1, the coding was 1.",
    "Custom codes used in the work.",
    "The first eleven measures were manually coded from the ACAPS dataset.",
    "Each line of coding identifies the measure to be coded, the scale of the measure, the targeted country and the period for which the measure is implemented.",
    "We are aware that collecting data from other sources might lead to the importation of any measurement issues they bring with them.",
    "A research assistant double checked manually, re-reading all the lines reported in ACAPS country per country, that the coded measures were accurate between October 25 and November 6, 2020.",
    "School closures were directly taken from the UNESCO dataset which indicates on which scale schools are closed (local level, national-level or no school closures).",
    "This coding allows researchers to differentiate the degrees of implementation of the measures.",
    "This graphical check was run for the 37 OECD countries."
  ],
  "embedding_config": {
    "client": "INSTRUCTOR(\n  (0): Transformer({'max_seq_length': 512, 'do_lower_case': False}) with Transformer model: T5EncoderModel \n  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False})\n  (2): Dense({'in_features': 1024, 'out_features': 768, 'bias': False, 'activation_function': 'torch.nn.modules.linear.Identity'})\n  (3): Normalize()\n)",
    "model_name": "hkunlp/instructor-large",
    "cache_folder": null,
    "model_kwargs": {},
    "embed_instruction": "Represent the sentence for retrieval optimized for answering questions on the mention of data; Input: ",
    "query_instruction": "Represent the question for retrieving the most relevant sentence mentioning data; Input: "
  },
  "vectorstore_cls": "Qdrant",
  "doc_options": {
    "skip_urls": true,
    "min_sentence_len": 25
  }
}